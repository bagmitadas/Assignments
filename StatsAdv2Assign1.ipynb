{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNinPiNiC24VpSZvYM3MyBO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["1.Explain the properties of the F-distribution.  "],"metadata":{"id":"GzEPzV2WdaT-"}},{"cell_type":"markdown","source":["Answer: The F-Distribution is a continuous probability distribution that has a non-negative range of values. It is a ratio of two independent chi-square distributions, each divided by their degrees of freedom. The F-Distribution has two parameters, the numerator degrees of freedom (df1) and the denominator degrees of freedom (df2). The probability density function (PDF) of the F-Distribution is given by:\n","f(x) = ((df1/2) * (df2/2)) / (B((df1/2), (df2/2))) * (x^((df1/2) - 1)) * ((1 + (df1*x/df2))^(-(df1+df2)/2))\n","where B is the Beta function, which is defined as:\n","B(x,y) = (gamma(x) * gamma(y)) / gamma(x+y)\n","where gamma is the gamma function.\n","\n","Properties of the F-distribution:\n","There are several properties of F-distribution which are explained below:\n","•\tThe F-distribution is positively skewed and with the increase in the degrees of freedom ν1 and ν2, its skewness decreases.\n","•\tThe value of the F-distribution is always positive, or zero since the variances are the square of the deviations and hence cannot assume negative values. Its value lies between 0 and ∞.\n","•\tThe statistic used to calculate the value of mean and variance is:\n","Mean = df2 / (df2 - 2) (when df2 > 2)\n","Variance = (2 * (df2^2) * (df1 + df2 - 2)) / (df1 * (df2 - 2)^2 * (df2 - 4)) (when df2 > 4)\n","•\tThe shape of the F-distribution depends on its parameters ν1 and ν2 degrees of freedom.\n","•\tThe values of the area lying on the left-hand side of the distribution can be found out by taking the reciprocal of F values corresponding to the right-hand side and the degrees of freedom in the numerator and the denominator are interchanged. This is called as Reciprocal Property of F-distribution. Symbolically, it can be represented as:\n","F1 – a, v1,v2 = 1 / Fa, v2, v1\n","This property is mainly used in the situations when the values of the lower tail F values are to be determined corresponding to the upper tail F values.\n","Thus, these are the properties of F-distribution that tells how the sample is distributed under study and what statistical inferences can be drawn therefrom.\n"],"metadata":{"id":"by17gYc4diEm"}},{"cell_type":"markdown","source":["2. In which types of statistical tests is the F-distribution used, and why is it appropriate for these tests?"],"metadata":{"id":"3858tNGSdm-O"}},{"cell_type":"markdown","source":["Answer:\n","The F-distribution is a continuous probability distribution that arises frequently in statistical hypothesis testing. It's particularly useful for comparing variances between two populations or multiple groups.   \n","Types of Statistical Tests using F-Distribution:\n","•\tAnalysis of Variance (ANOVA):\n","Analysis of Variance (ANOVA) is a statistical technique used to compare the means of two or more groups. It helps determine whether there are significant differences between the means of these groups.\n","Types of ANOVA:\n","-\tOne-Way ANOVA:\n","o\tCompares the means of three or more independent groups.\n","o\tAssumes that the populations have equal variances (homogeneity of variance).\n","o\tNull Hypothesis (H₀): All group means are equal.\n","o\tAlternative Hypothesis (H₁): At least one group mean is different.\n","\n","-\tTwo-Way ANOVA:\n","o\tExamines the effects of two categorical independent variables on a continuous dependent variable.\n","o\tIt considers the main effects of each factor and their interaction effect.\n","-\tRepeated Measures ANOVA: Compares the means of multiple groups for the same subjects over time.\n","Testing Equality of Variances:\n","The F-test for equality of variances is a statistical test used to determine whether two populations have equal variances. It's often used as a preliminary test before conducting t-tests or ANOVA, as these tests assume equal variances.\n","F-test for Equality of Variances: Used to compare the variances of two populations.   \n","Why is the F-distribution appropriate for these tests?\n","The F-distribution arises naturally when comparing variances of two populations or multiple groups. It's derived from the ratio of two independent chi-square distributions, each divided by its respective degrees of freedom.\n"],"metadata":{"id":"qF9oYv3Edpzp"}},{"cell_type":"markdown","source":[" 3. What are the key assumptions required for conducting an F-test to compare the variances of two populations?"],"metadata":{"id":"DhzZFK6vdrdk"}},{"cell_type":"markdown","source":["Answer:\n","To ensure the validity of the F-test for equality of variances, the following assumptions must be met:\n","Independence: The two samples must be independent of each other.\n","Normality: Both populations from which the samples are drawn should be normally distributed.\n","The F-test is sensitive to departures from normality, especially when sample sizes are small. In such cases, alternative tests like Levene's test can be more robust.\n"],"metadata":{"id":"JBcDAbwHdu2c"}},{"cell_type":"markdown","source":["4. What is the purpose of ANOVA, and how does it differ from a t-test?  "],"metadata":{"id":"NLwn-QYZdyIL"}},{"cell_type":"markdown","source":["Answer:\n","The primary purpose of ANOVA (Analysis of Variance) is to determine whether there are statistically significant differences between the means of two or more groups. It is used to compare the means of different groups and assess if the observed differences are due to chance or a real effect.   \n","Uses of ANOVA:\n","\n","-\tComparing Treatment Effects: Evaluating the effectiveness of different treatments or interventions.   \n","-\tAnalyzing Experimental Designs: Examining the impact of independent variables on a dependent variable.   \n","-\tIdentifying Significant Differences: Determining which groups have significantly different means.   \n","Examples:\n","-\tA pharmaceutical company might use ANOVA to compare the effectiveness of three different drugs on a particular disease.   \n","-\tAn educator might use ANOVA to compare the test scores of students in different teaching methods.   \n","-\tA marketer might use ANOVA to compare the sales performance of different marketing campaigns.\n","By understanding the differences between group means, ANOVA helps researchers and analysts make informed decisions and draw meaningful conclusions.\n","\n","Difference between ANOVA and T-Test\n","-\tANOVA is an observable technique used to compare the means of more than two population groups. But, t-test is statistical hypothesis test used to compare the means of two population groups.\n","-\tANOVA equates three or more such groups. Whereas, t-test compares two sample sizes (n) both below 30.\n","-\tANOVA has more error risks as comparative to t-test.\n","-\tANOVA is one-sided test due to no negative variance. But, t-test can be performed in a double-sided or single-sided test.\n","-\tANOVA is used for huge population counts whereas; t-test is used when the population is less than 30.\n"],"metadata":{"id":"dwjIPpM3d1S_"}},{"cell_type":"markdown","source":["5. Explain when and why you would use a one-way ANOVA instead of multiple t-tests when comparing more than two groups.\n"],"metadata":{"id":"6W_nyoB4d26l"}},{"cell_type":"markdown","source":["Answer:\n","There are several reasons to use ANOVA instead of multiple t-tests when comparing more than two groups which were discussed below:\n","Controlling Type or Error Rate:\n","-\tWhen conducting multiple t-tests, the overall Type I error rate (the probability of incorrectly rejecting the null hypothesis) increases.   \n","-\tANOVA controls this error rate, ensuring that the overall significance level remains at a desired level (e.g., 0.05).   \n","Efficiency:\n","-\tANOVA is more efficient than multiple t-tests, especially when comparing many groups. It requires fewer calculations and reduces the risk of making Type I errors.   \n","Comprehensive Analysis:\n","-\tANOVA provides a single test statistic (F-statistic) to assess the overall significance of differences among group means.   \n","-\tIf the overall F-test is significant, you can then use post-hoc tests (like Tukey's HSD or Bonferroni correction) to identify specific pairwise differences.   \n","At the end of explanation we can say, while multiple t-tests can be used to compare means of multiple groups, ANOVA is a more powerful and statistically sound approach. It allows for a more comprehensive analysis and helps control the overall Type or error rate.\n"],"metadata":{"id":"3Etf47KBd5qX"}},{"cell_type":"markdown","source":["6. Explain how variance is partitioned in ANOVA into between-group variance and within-group variance. How does this partitioning contribute to the calculation of the F-statistic?"],"metadata":{"id":"BRaWndkDd7XN"}},{"cell_type":"markdown","source":["Answer:\n","In ANOVA, the total variance in a dataset is partitioned into two components:\n","-\tBetween-Group Variance: This represents the variability between the means of different groups. It measures how different the group means are from each other.\n","o\tLarger between-group variance suggests that the group means are significantly different.\n","Within-Group Variance:\n","\n","-\tThis represents the variability within each group. It measures the spread of data points within each group.\n","-\tSmaller within-group variance indicates that the data points within each group are more similar.\n","The F-statistic:\n","The F-statistic is calculated by comparing the ratio of these two variances:\n","F-statistic = Between-group variance / Within-group variance\n","\n","A larger F-statistic indicates that the between-group variance is significantly larger than the within-group variance. This suggests that the differences between the group means are likely not due to chance, but rather to the factor being studied.   \n","In essence, the F-statistic is a measure of how much of the total variation in the data can be explained by the group differences. A higher F-statistic suggests that the group differences are more likely to be real and not due to random chance.\n","By calculating the F-statistic and comparing it to a critical value from the F-distribution, we can determine whether the differences between group means are statistically significant."],"metadata":{"id":"OeQuLXcyd-Vs"}},{"cell_type":"markdown","source":["7. Compare the classical (frequentist) approach to ANOVA with the Bayesian approach. What are the key differences in terms of how they handle uncertainty, parameter estimation, and hypothesis testing?"],"metadata":{"id":"Y--tIaTcd_z7"}},{"cell_type":"markdown","source":["Answer:\n","Comparison between Classical and Bayesian ANOVA\n","Classical ANOVA\n","-\tFrequentist Approach: Relies on fixed parameters and probability distributions of the data.\n","-\tNull Hypothesis Testing: Tests a specific null hypothesis (e.g., all group means are equal) against an alternative hypothesis.   \n","-\tP-values: Uses p-values to assess the significance of the results.   \n","-\tFixed Effects: Assumes that the effects of the independent variables are fixed and not random.\n","-\tInference: Makes inferences about the population based on sample data.   \n","Bayesian ANOVA\n","-\tBayesian Approach: Incorporates prior beliefs about the parameters and updates them based on the observed data.   \n","-\tPosterior Distribution: Calculates the posterior distribution of the parameters, representing the updated beliefs after observing the data.\n","-\tCredible Intervals: Provides a range of plausible values for the parameters with a specified level of credibility.   \n","-\tModel Comparison: Uses Bayes factors to compare the evidence for different models.   \n","-\tFlexible Modeling: Can accommodate complex models with prior information and hierarchical structures.\n","\n","Key Differences between Classical and Bayesian ANOVA\n","\n","Uncertainty:\n","-\tClassical ANOVA: Treats parameters as fixed, unknown quantities. Uncertainty is assessed using p-values and confidence intervals, which are based on the sampling distribution of the test statistic.\n","-\tBayesian ANOVA: Treats parameters as random variables with probability distributions. Uncertainty is quantified using probability distributions, specifically the posterior distribution.   \n","\n","Parameter Estimation:\n","-\tClassical ANOVA: Uses point estimates (e.g., sample means) to estimate population parameters.\n","-\tBayesian ANOVA: Uses prior beliefs about the parameters, combined with the observed data, to obtain posterior distributions for the parameters. These posterior distributions represent the updated beliefs about the parameters after considering the data.   \n","\n","Hypothesis Testing:\n","-\tClassical ANOVA: Relies on p-values to assess the significance of the results. A small p-value indicates strong evidence against the null hypothesis.   \n","-\tBayesian ANOVA: Uses Bayes factors to compare the evidence for different hypotheses. A higher Bayes factor indicates stronger evidence for one hypothesis over another.   \n","\n","At the end it can be concluded that Classical ANOVA focuses on fixed parameters and uses hypothesis testing to make inferences and Bayesian ANOVA incorporates prior beliefs and provides a more probabilistic approach to inference\n"],"metadata":{"id":"5cRNEaiOeEFS"}},{"cell_type":"markdown","source":["8. Question: You have two sets of data representing the incomes of two different professions\n","Profession A: [48, 52, 55, 60, 62]\n","Profession B: [45, 50, 55, 52, 47]\n","Perform an F-test to determine if the variances of the two professions' incomes are equal. What are your conclusions based on the F-test?\n","Task: Use Python to calculate the F-statistic and p-value for the given data.\n","Objective: Gain experience in performing F-tests and interpreting the results in terms of variance comparison.\n"],"metadata":{"id":"pybwMJUleGXV"}},{"cell_type":"code","source":["import scipy.stats as stats\n","\n","# Sample data\n","profession_a = [48, 52, 55, 60, 62]\n","profession_b = [45, 50, 55, 52, 47]\n","\n","# Perform F-test for equality of variances\n","f_statistic, p_value = stats.f_oneway(profession_a, profession_b)\n","\n","print(\"F-statistic:\", f_statistic)\n","print(\"p-value:\", p_value)\n","\n","# Set significance level\n","alpha = 0.05\n","\n","if p_value < alpha:\n","    print(\"Reject the null hypothesis. Variances are significantly different.\")\n","else:\n","    print(\"Fail to reject the null hypothesis. Variances are not significantly different.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kkEPwxNhJm6f","executionInfo":{"status":"ok","timestamp":1730723395568,"user_tz":-330,"elapsed":2039,"user":{"displayName":"Bagmita Das","userId":"03415844889242775643"}},"outputId":"fd4a8a87-30a7-4c22-b836-2bf390c235a7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["F-statistic: 3.232989690721649\n","p-value: 0.10987970118946545\n","Fail to reject the null hypothesis. Variances are not significantly different.\n"]}]},{"cell_type":"markdown","source":["9. Question: Conduct a one-way ANOVA to test whether there are any statistically significant differences in average heights between three different regions with the following data.\n","Region A: [160, 162, 165, 158, 164]\n","Region B: [172, 175, 170, 168, 174]\n","Region C: [180, 182, 179, 185, 183]\n","Task: Write Python code to perform the one-way ANOVA and interpret the results\n","Objective: Learn how to perform one-way ANOVA using Python and interpret F-statistic and p-value\n"],"metadata":{"id":"mCZ_VX0-eR_G"}},{"cell_type":"code","source":["import scipy.stats as stats\n","\n","# Sample data\n","region_a = [160, 162, 165, 158, 164]\n","region_b = [172, 175, 170, 168, 174]\n","region_c = [180, 182, 179, 185, 183]\n","\n","# Perform one-way ANOVA\n","f_statistic, p_value = stats.f_oneway(region_a, region_b, region_c)\n","\n","print(\"F-statistic:\", f_statistic)\n","print(\"p-value:\", p_value)\n","\n","# Set significance level\n","alpha = 0.05\n","\n","if p_value < alpha:\n","    print(\"Reject the null hypothesis. There is a significant difference between the means of the three regions.\")\n","else:\n","    print(\"Fail to reject the null hypothesis. There is no significant difference between the means of the three regions.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DqGq9didKIba","executionInfo":{"status":"ok","timestamp":1730723502767,"user_tz":-330,"elapsed":521,"user":{"displayName":"Bagmita Das","userId":"03415844889242775643"}},"outputId":"99d5c80b-f268-46a8-b051-6e231cf5167c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["F-statistic: 67.87330316742101\n","p-value: 2.870664187937026e-07\n","Reject the null hypothesis. There is a significant difference between the means of the three regions.\n"]}]}]}